---
title: "Segregation Empirical Work"
author: "Erik B. Johnson"
date: "`r format(Sys.time(), '%d %B, %Y')`"
header-includes: 
  - \usepackage{dcolumn}
urlcolor: "blue"
output: 
    pdf_document:
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(zipcode)
library(ggmap)
library(googleway)
library(data.table)
library(rgdal)
library(rgeos)
library(utils)
library(stringr)
library(xtable)
library(stargazer)
library(seg)
library(transport)
library(stats) # For reshape
library(rgdal)
library(maptools)
library(plyr)
suppressMessages(library(bit64))


#source('locations.segregation.R')
#load('~/Dropbox/pkg.data/api.keys/raw/l.pkg.rdata')
#api.key <- l.pkg$google

library(tidycensus)
library(tidyverse)
#for Karl
api_key<-"f4ea45dde45d543afab05aa7ce86b36d5992a42f"
census_api_key("f4ea45dde45d543afab05aa7ce86b36d5992a42f")

# File Locations
combs.richmond.centroids.location <- 'CleanData/combs.richmond.centroids.rdata'
dists.richmond.location <- 'CleanData/dists.richmond.rdata'
dists.richmond.new.location <- 'CleanData/dists.richmond.new.rdata'
dists.richmond.raw.new.location <- 'CleanData/dists.richmond.raw.new.rds'
census.location <- 'CleanData/census.rdata'
census.commute.location<- 'CleanData/census.commute.rdata'
census.income.location <- 'CleanData/census.income.rdata'
census.race.location <- 'CleanData/census.race.rdata'
measures.wasserstein.location <- 'CleanData/measures.wassersteing.rds'
shapes.richmond.tracts.location <- 'CleanData/shapes.richmond.tracts.rdata'
shapes.richmond.centroids.location <- 'CleanData/shapes.richmond.centroids.rdata'
shapes.proj.env.location <- 'CleanData/shapes.proj.env.rds'

f_list <- paste0('R/', list.files('R'))
for(file in f_list){
    cat(file, '\n')
    source(file)
}
```

# Description

Data work and documentation for the Richmond transportation/segregation paper.

# Background

Really seems that we should focus on the commuting component of transportation (empirical and theoretical reasons.)

This is a list of possible sources to help motivate our paper.

*   [Commuting to Opportunity](`r URLencode('https://web.stanford.edu/group/scspi/_media/pdf/key_issues/transportation_policy.pdf')`)
*   [Commuting in America](`r URLencode('http://traveltrends.transportation.org/Documents/CA10-4.pdf')`)
*   [Low income commuters and Cycling](`r URLencode('https://www.citylab.com/transportation/2014/07/how-low-income-commuters-view-cycling/374390/')`)

\clearpage

# Data

## Change in Travel times
```{r dists.richmond, echo=FALSE}
l_dists_richmond <- funDistances_combine()
```

First, use google travel times to build \textbf{dists.richmond} for distances (meters) and travel times (seconds) by mode to and from all census tracts.
Based on tract-centroids to tract-centroids. Distance is non-euclidean. For google distance and time calculation documentation see: 
[Google distance api documentation](`r URLencode('https://developers.google.com/maps/documentation/distance-matrix/intro')`)

Summary statistics for \textbf{dists.richmond} (where NA transit values default to walking values):
```{r results='asis', echo=FALSE}
dt_dists <- rbindlist(l_dists_richmond, use.names=TRUE, fill=TRUE)
dt_cast <- dcast(dt_dists, origin.tract + dest.tract ~ mode + scrapeDate, value.var='distance_seconds')
stargazer(dt_cast, summary=TRUE, header=FALSE, nobs=FALSE, digits=0, align=T, style='qje', title=paste0('Pairwise Distance Summary'))
```

Change in Travel times

```{r results='asis', echo=FALSE}

# Fix dt_transit for Karl (regression)
# Create dt_transit from karl2017 and karl2019 but first create mean travel time for each origin tract

dt_transit <- dt_cast[, .(origin.tract, dest.tract, seconds2017 = `transit_03-2017`, seconds2018 = `transit_03-2018`)]
dt_transit <- dt_transit[, pct_increase:=(seconds2018-seconds2017)/seconds2017]
dt_transit <- dt_transit[pct_increase != 0]
ggplot2::ggplot(dt_transit, aes(pct_increase*100)) + geom_histogram(bins=50) + xlab('Percent change tract to tract Public Transit Times 2017 to 2019') + geom_vline(xintercept=0, color='white')

#y<-dt_transit[,"pct_increase"]
#y<-y$pct_increase
#x<-1:length(y)
#plot(y~x)

ggsave('Figures/hist_pctChng_transitTimes.pdf')
```


# Which tracts have the largest changes in travel times?

Nobody cares about public transportation because $u(x_1,x_2)$


```{r results='asis', echo=FALSE}
dt_origin_changes <- dt_transit[, .(mean_pct_increase=mean(pct_increase), sd_pct_increase=sd(pct_increase)), by=origin.tract][order(-mean_pct_increase)]

#dt_origin_changes2 <- dt_transit[, .(mean_pct_increase=mean(pct_increase), sd_pct_increase=sd(pct_increase)), by=origin.tract]

y<-dt_origin_changes$mean_pct_increase
x<-1:length(y)
plot(y~x) #Why is this in order largest to smallest?

#save for regression before fortifying
dt_origin_changes_reg<-dt_origin_changes
setnames(dt_origin_changes_reg, 'origin.tract', 'id')

# Plot these
shps <- funShapes.richmond.tracts()
shp_fortify <- fortify(shps, region='GEOID')
setnames(dt_origin_changes, 'origin.tract', 'id')
dt_origin_changes <- dt_origin_changes[, cut_pct_increase:=pmin(mean_pct_increase,0.20)]
dt_origin_changes <- dt_origin_changes[, cut_pct_increase:=pmax(cut_pct_increase,-0.20)]
tracts.df <- join(dt_origin_changes, shp_fortify, by='id')
census <- funCensus()
setnames(census, 'tract', 'id')
tracts.df <- join(census, tracts.df, by='id')
tracts.df$pct_black <- tracts.df$race.black.n/tracts.df$race.total.n

tracts.df$totnohisp<-tracts.df$race.total.n-tracts.df$race.hispanic.n
tracts.df$pct_black_no_hisp<-tracts.df$race.black.n/tracts.df$totnohisp



tracts.df<-tracts.df[,cut_pct_black:=pmin(pct_black, 0.6)]
tracts.df<-tracts.df[,cut_pct_black:=pmax(pct_black,0.0)]
ggplot(tracts.df, aes(long, lat, group=group, fill=mean_pct_increase)) +  geom_polygon() + coord_equal() 
ggplot(tracts.df, aes(long,lat, group=group, fill=pct_black))+geom_polygon() + coord_equal()

testplot.time<-ggplot(tracts.df, aes(long, lat, group = group, fill = cut_pct_increase)) + scale_fill_gradient2(low ='dark green', mid = "white", high = "red", 
                       midpoint = 0.0, space = "rgb", na.value = "white", 
                       guide = ('colourbar'), guide_legend(title = 'Pct Change in Travel Time')) + geom_polygon() + coord_equal()
testplot.time

testplot.race<-ggplot(tracts.df, aes(long, lat, group = group, fill = pct_black_no_hisp)) + scale_fill_gradient2(low ='light yellow', mid = "gray", high = "black", 
                       midpoint = 0.4, space = "rgb", na.value = "white", 
                       guide = ('colourbar'), guide_legend(title = 'Pct of Population is Black')) + geom_polygon() + coord_equal()
testplot.race #Race is screwed up, with a very low max for pct_black, need to use no_hisp

par(mfrow=c(1,2))
testplot.time
testplot.race
par(mfrow = c(1,1))

t#reg stuff
test.df<-join(dt_origin_changes_reg,census, by ='id')

y<-test2[,2]
y<-y*100
black<-test2[,11]
test2$pctblack<-test2$race.black.n/test2$race.total.n
test2$nohisp<-test2$race.total.n - test2$race.hispanic.n


#pctblack<-test2[,29]
inc<-test2$income.med.hh
pctwhite<-test2$race.white.n/test2$nohisp
pctasian<-test2$race.asian.n/test2$nohisp
pcthisp<-test2$race.hispanic.n/test2$nohisp #this becomes NA in all regressions
pctblack2<-test2$race.black.n/test2$nohisp

reg.hope<-lm(y~pctblack2 + pctwhite)
summary(reg.hope) # VERY LOW r^2

meantime<-test2[,9]

pctpub<-test2$industry.public.admin.n/test2$industry.total.industry.n
pctaffhm<-test2$industry.affhm.n/test2$industry.total.industry.n
pctcons<-test2$industry.construction.n/test2$industry.total.industry.n
pctmanu<-test2$industry.manufacturing.n/test2$industry.total.industry.n
pctwhole<-test2$industry.wholesale.n/test2$industry.total.industry.n
pctretail<-test2$industry.retail.n/test2$industry.total.industry.n
pctTAW<-test2$industry.transportation.and.warehouse.n/test2$industry.total.industry.n
pctinfo<-test2$industry.information.n/test2$industry.total.industry.n
pctfinance<-test2$industry.finance.n/test2$industry.total.industry.n
pctSW<-test2$industry.science.waste.n/test2$industry.total.industry.n
pcteduhealth<-test2$industry.education.healthcare.n/test2$industry.total.industry.n
pctarts<-test2$industry.arts.n/test2$industry.total.industry.n
pctother<-test2$industry.other.n/test2$industry.total.industry.n

totwork<-test2$industry.total.industry.n

pct.bus<-test2$bus.n/test2$race.total.n
pct.walk<-test2$walk.n/test2$race.total.n
pct.car<-test2$car.n/test2$race.total.n
pct.carpool<-test2$carpool.n/test2$race.total.n

regind<-lm(y~pctwhole) # reduced model one by one, none of the industries were ever significant (or even close)
summary(regind)

regcom<-lm(y~pct.bus) # reduced model, none significant
summary(regcom)

regrace<-lm(y~pctasian) #This makes no sense
summary(regrace)


regall<-lm(y~pct.bus + pctblack + pctasian + pctwhite + totwork + inc + pctwhole + pcteduhealth + pctfinance + pctpub) 
#When I just throw a bunch of variables in the pctwhite and pctblack are far and away the worst
summary(regall)
#If I reduce model it goes down to pctasian and pct.bus, but still makes no sense
```

\clearpage

## Census [census]

The \textbf{census} dataset consists of the following fields:

```{r results='asis', echo=FALSE}
#census <- funCensus()
#stargazer(census, summary=TRUE, header=FALSE, nobs=FALSE, digits=0, align=T, style='qje', title='Tract Level Summary Statistics')
```

The construction of the census table is documented in Table \ref{dt.census}. For more specifics see \textit{funCensus.income, funCensus.commute, funCensus.race} in the file \texttt{functions.segregation.R}. 

```{r results='asis', echo=FALSE}
#cap <- '2011-2015 ACS 5-Year Estimates, Geography: Tract'
#x.out <- capture.output(print(xtable(funCensus.tables(), caption = cap, label='dt.census'),  include.rownames=FALSE, comment=FALSE, #caption.placement = 'top'))
#cat(x.out,sep = '\n')
```

\clearpage

# Measuring segregation

We begin by estimating the amount of segregation in the city with a variety of traditional segregation measures (from the R library \texttt{seg})\footnote{Documentation and explaination at (http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0113767) and Reardon and O'Sullivan (2004)}. Interestingly, there have been a variety of measures which include a variety of spatial terms that uses information on neighbors and shared borders. These measures are, however, fundamentally different from our new one since spatial distance is a matrix that incorporates a variety travel times between tracts over the entire city. 


## Dissimilarity
```{r, echo=FALSE, eval=FALSE}
dissimilarity <- funMeasures.dissimlarity(census)
```
We begin by calculating a simple dissimlarity index between two groups $X$ and $Y$ in locations $i$ described in Equation \eqref{eq:D}. Higher values of dissimilarity imply more wihtin tract race distributions. Note again that this measure is inherently aspatial and only uses the tract level census data. Note that the 'nb' term in \texttt{seg} library scales the interaction of the iteraction is normalized to 1 and not appropriate for our application. Additional information on the library can be found at the [Stanford Dissimilarity](http://stanford.edu/~ejdemyr/r-tutorials/segregation/). Empirical results are shown in Table \ref{tbl:D}. We can see that the most spatially dissimilar races according to this measure are with a value of

\begin{equation}\label{eq:D}
D = \frac{1}{2}\sum_{i=1}^n\left|\frac{x_i}{X}- \frac{y_i}{Y}\right|
\end{equation}

```{r tbl:D, results='asis', echo=FALSE, eval=FALSE}
cap <- 'Dissimilarity Index'
lab <- 'tbl:D'
x.out <- capture.output(print(xtable(dissimilarity, caption = cap, label=lab),  include.rownames=FALSE, comment=FALSE, caption.placement = 'top', round=2))
cat(x.out,sep = '\n')
```

## Wasserstein Measure
```{r, eval=FALSE}
wasserstein <- funMeasures.wasserstein(census, l_dists_richmond)
```

The two main drawbacks of the $D$ measure are the lack of spatial information (distance) between populations and the fact that there is no direction implied in the relationship. Next, we measure dissimilarity through a Wasserstein measure, which will include both the spatial information and has the ability to infer directional relationships in the form of an asymmetric graph. This is a two stage process and requires careful selection of counterfactuals.  We begin with the most simple formulation\footnote{The Wasserstein measure is found in the R  \texttt{transport} package.}.


```{r merge_files}
f_1 <- readRDS('CleanData/karl2017.rds')
f_2 <- readRDS('CleanData/karl2019.rds')
dt <- rbindlist(list(f_1, f_2), use.names=TRUE)

dt_agg <- dt[, lapply(.SD, mean), by=.(origin.tract, year), .SDcols = c('driving', 'transit', 'walking', 'weighted')]

dt_cast <- dcast(dt_agg, origin.tract ~ year, value.var=c('driving', 'transit', 'walking', 'weighted'))
saveRDS(dt_cast, file='CleanData/karlMerge.rds')

```

